library(funModeling)
library(stats)
library(olsrr)
load("C:/Users/ARI/Desktop/ITBA/4.Análisis de Datos/TP4/acath.sav")
attach(acath)
acath$sex <- factor(acath$sex)
acath_glm <- glm(sigdz ~  choleste, data = acath, family = "binomial")
summary(acath_glm)
newdata = data.frame(choleste=199)
prediccion <- predict(acath_glm, newdata, type = 'response')
prediccion
acath_glm2 <- glm(sigdz ~  choleste + age + cad.dur, data = acath, family = "binomial")
summary(acath_glm2)
acath_glm3 <- glm(sigdz ~  choleste + age + cad.dur + sex, data = acath, family = "binomial")
summary(acath_glm3)
x = seq(1, 11, 0.1)
gpa = 1
y =  exp(-3.98 + 0.002* 1 + 0.8 *x - 0.67)/(1 + exp(-3.98 + 0.002 *1 + 0.8 *x - 0.67))
qplot(x , y , geom = "line", xlab = "gre",ylab = "Probabilidad de ser admitido", main = "Probabilidad de ser admitido cuando gpa = 1")
Caseros <- c(11,14,7,15,11,13,11,16,10,15,18,12,9,9,10,10,15,10,14,
10,10,12,14,12,15,7,13,6,10,15,20,10,13,10,6,14,8,10,8,11)
Santos_Lugares <- c(13,10,12,7,5,10,10,16,9,7,7,2,6,9,9,8,8,10,3,6,5,2,
9,3,4,5,10,8,5,9,10,8,13,10,0,2,1,1,0,4)
Pablo_Podesta <- c(6,7,3,5,9,6,1,6,0,2,5,6,11,6,7,0,5,7,5,4,7,4,2,8,9,
6,1,4,7,7,8,9,7,5,1,6,9,4,7,6)
Asistencia <- c(Caseros, Santos_Lugares, Pablo_Podesta)
Localidad <- c(rep("Caseros",length(Caseros)),rep('Santos Lugares',length(Santos_Lugares)),
rep('Pablo Podesta',length(Pablo_Podesta)))
datos<- data.frame(Localidad = factor(Localidad ,
labels= c('Caseros','Santos Lugares','Pablo Podesta')),Asistencia)
plot(datos, col = "violet", main="Gráfico XXX. Boxplot: Asistencia según localidad del estudiante")
tapply(datos$Asistencia,datos$Localidad,mean)
library(gplots)
plotmeans(Asistencia~Localidad, col = "violet", main="Gráfico XXX. Plotmeans según localidad")
library(gplots)
res<-aov(Asistencia ~ Localidad,data=datos)
res_summary <- summary(res)
summary(res)
desviaciones <- tapply(res$residuals, Localidad, sd)
max(desviaciones)/min(desviaciones)
plot(res$residuals, col = "blue", main="Gráfico XXX. Valores de los residuos", xlab="Índice", ylab="Valor del residuo")
dfr <- data.frame(Residuos = res$residuals)
ggplot(dfr, aes(x = Residuos)) +
labs(title="Gráfico XXX. Distribución empírica y teórica de los residuos", y="Densidad")+
geom_histogram(aes(y =..density..),
breaks = seq(-10, 10, by = 1),
colour = "black",
fill = "white") +  geom_density(size= 1.2,colour = "blue") +
stat_function(fun = dnorm,  args = list(mean = mean(res$residuals),
sd = sd(res$residuals)),colour = "green", size = 1.2)
shapiro_residuals <- shapiro.test(res$residuals)
shapiro.test(res$residuals)
Tukey_results <- TukeyHSD(res)
print(TukeyHSD(res))
tuk_plot <- function (x, xlab, ylab, ylabels = NULL, ...) {
for (i in seq_along(x)) {
xi <- x[[i]][, -4L, drop = FALSE]
yvals <- nrow(xi):1L
dev.hold()
on.exit(dev.flush())
plot(c(xi[, "lwr"], xi[, "upr"]), rep.int(yvals, 2L),
type = "n", axes = FALSE, xlab = "", ylab = "", main = NULL,
...)
axis(1, ...)
# change for custom axis labels
if (is.null(ylabels)) ylabels <- dimnames(xi)[[1L]]
axis(2, at = nrow(xi):1, labels = ylabels,
srt = 0, ...)
abline(h = yvals, lty = 1, lwd = 0.5, col = "lightgray")
abline(v = 0, lty = 2, lwd = 0.5, ...)
segments(xi[, "lwr"], yvals, xi[, "upr"], yvals, ...)
segments(as.vector(xi), rep.int(yvals - 0.1, 3L), as.vector(xi),
rep.int(yvals + 0.1, 3L), ...)
title(main = paste0("Gráfico XXX. Test de Tukey, ",format(100 * attr(x, "conf.level"),
digits = 2L), "% Nivel de confianza\n"),
# change for custom axis titles
xlab = xlab, ylab = ylab)
box()
dev.flush()
on.exit()
}
}
tuk_plot(TukeyHSD(res), "Diferencia de medias según localidad", "Localidades", c("SLug-Csros", "PP-Csros", "PP-SLug"))
data(nottem)
nottem <- ts(nottem,frequency = 12, start = c(1920,1), end = c(1939,12))
#Fecha inicial (primeros tres valores):
start(nottem) #La fecha inicial es el período 1
#Fecha final (últimos tres valores):
end(nottem) #La fecha final es el periodo 240
#Temperatura inicial (primeros tres valores):
window(nottem,start=c(1920,1),end=c(1920,6))
#Temperatura final (ultimos tres valores):
window(nottem,start=c(1939,7),end=c(1939,12))
plot(nottem, col = "black", main="Gráfico XXX. Serie de tiempo nottem (ene-1920/dic-1939)", xlab="Período", ylab="Temperatura promedio en Nottinham")
plot(nottem, col="black", main = "Gráfico XXX. Tendencia de la serie nottem", ylab = "Temperatura (observada y tendencia)", xlab = "Tiempo")
lines(aggregate(nottem,FUN=mean,fill=NA), col="blue")
boxplot(nottem~cycle(nottem), main = "Gráfico XXX. Cajas para cada mes del año; serie nottem", xlab="Número de mes del año", ylab="Temperatura", col ="green")
#El comando cycle determina la unidad de tiempo a la que pertenece cada observacion de la serie:
#cycle(nottem) # Ver ejemplo ARIMA en el modelo 3
ggseasonplot(nottem, col=rainbow(12), year.labels=FALSE, main = "Gráfico XXX. Gráfico estacional (serie nottem; ene-1920/dic-1939)")+
theme(legend.position = "bottom")
#scale_colour_discrete(name="Año")
#+ guides(color=guide_legend(title="Año"))
#+ scale_color_discrete(name= "Año", labels= paste0("19",20:39))
#seasonplot(nottem, col=rainbow(12), year.labels=TRUE)
nottem.desc = decompose(nottem)
#plot(nottem.desc, main= "Descomposicion aditiva de la serie nottem", xlab='Tiempo')
autoplot(decompose(nottem, type = "additive"))+
labs(y="Temperatura", x="Tiempo") +
ggtitle("Descomposicion aditiva de nottem") +
theme(plot.title=element_text(hjust=0.5))
library(tseries)
nottem_sa <- nottem.desc$x-nottem.desc$seasonal
adf.test(nottem_sa)
tiempo.dado.f = length(nottem) #Cantidad de observaciones de la serie de tiempo nottem
nottem_train = ts(nottem[1:(tiempo.dado.f-12)],frequency=12,start=c(1920,1)) #Datos de training
nottem_forecast = ts(nottem[(tiempo.dado.f-12+1):tiempo.dado.f],
frequency=12,start=c(1939,1)) #Datos para testeo
modelo<- auto.arima(nottem_train, stationary = FALSE, seasonal = TRUE)
# Si los datos tienen un patrón estacional cada trimestre, entonces ARIMA obtiene un orden (p, d, q) para todos los puntos y un (P, D, Q) para cada trimestre.
summary(modelo)
#Pronostico
ajuste.final <- forecast(modelo, h=12)
# ajuste.final
#valores ajustados
# ajuste.final$mean
# plot(ajuste.final)
# print(ajuste.final)
pronosticos = cbind(nottem_forecast,round(ajuste.final$mean,2),round(nottem_forecast - ajuste.final$mean,2))
#pronosticos$error <- pronosticos[,2] - pronosticos[,1]
colnames(pronosticos) <- c("Observados", "Pronosticados (modelo ARMA)", "Error de pronóstico")
pronosticos
plot(nottem, main="Gráfico XXX. Temp. observadas y pronosticadas (ene-1920/dic-1939)",xlab="Tiempo", ylab="Temperatura")
lines(ajuste.final$mean, col="red")
recm <- sqrt ((1/12)* sum((ajuste.final$mean - nottem_forecast)^2))
recm
qplot(x , y , geom = "line", xlab = "gre",ylab = "Probabilidad de ser admitido", main = "Probabilidad de ser admitido cuando gpa = 1")
View(acath)
plot(x , y , geom = "line", xlab = "colesterol",ylab = "Probabilidad de estrechamiento de arteria", main = "Probabilidad de estrechamiento con promedio de edad y duración")
qplot(x , y , geom = "line", xlab = "colesterol",ylab = "Probabilidad de estrechamiento de arteria", main = "Probabilidad de estrechamiento con promedio de edad y duración")
qplot(x , y , geom = "line", xlab = "colesterol",ylab = "Probabilidad de estrechamiento de arteria", main = "Probabilidad de estrechamiento con promedio de edad y duración")
qplot(x , y , geom = "line", xlab = "colesterol",ylab = "Probabilidad de estrechamiento de arteria", main = "Probabilidad de estrechamiento con prom. de edad y duración")
plot(x , y , type = "line", xlab = "colesterol",ylab = "Probabilidad de estrechamiento de arteria", main = "Probabilidad de estrechamiento con prom. de edad y duración")
View(acath_glm3)
plot(x , masculino , type = "line", xlab = "colesterol",ylab = "Probabilidad de estrechamiento de arteria", main = "Prob. de estrechamiento con prom. de edad y duración")
lines(x, femenino)
masculino =  exp(acath_glm3[["coefficients"]][["(Intercept)"]] + acath_glm3[["coefficients"]][["age"]]*mean(acath$age) + acath_glm3[["coefficients"]][["choleste"]] *x + acath_glm3[["coefficients"]][["cad.dur"]] * mean(acath$cad.dur))/(1 + exp(acath_glm3[["coefficients"]][["(Intercept)"]] + acath_glm3[["coefficients"]][["age"]]*mean(acath$age) + acath_glm3[["coefficients"]][["choleste"]] *x + acath_glm3[["coefficients"]][["cad.dur"]] * mean(acath$cad.dur)))
femenino =  exp(acath_glm3[["coefficients"]][["(Intercept)"]] + acath_glm3[["coefficients"]][["age"]]*mean(acath$age) + acath_glm3[["coefficients"]][["choleste"]] *x + acath_glm3[["coefficients"]][["cad.dur"]] * mean(acath$cad.dur) + acath_glm3[["coefficients"]][["sex1"]])/(1 + exp(acath_glm3[["coefficients"]][["(Intercept)"]] + acath_glm3[["coefficients"]][["age"]]*mean(acath$age) + acath_glm3[["coefficients"]][["choleste"]] *x + acath_glm3[["coefficients"]][["cad.dur"]] * mean(acath$cad.dur) + acath_glm3[["coefficients"]][["sex1"]]))
plot(x , masculino , type = "line", xlab = "colesterol",ylab = "Probabilidad de estrechamiento de arteria", main = "Prob. de estrechamiento con prom. de edad y duración")
lines(x, femenino)
x
View(acath)
x = seq(min(choleste), max(choleste), 10000)
x = seq(min(choleste, na.rm = TRUE), max(choleste, na.rm = TRUE), 10000)
x = seq(min(choleste, na.rm = TRUE), max(choleste, na.rm = TRUE), 0.1)
masculino =  exp(acath_glm3[["coefficients"]][["(Intercept)"]] + acath_glm3[["coefficients"]][["age"]]*mean(acath$age) + acath_glm3[["coefficients"]][["choleste"]] *x + acath_glm3[["coefficients"]][["cad.dur"]] * mean(acath$cad.dur))/(1 + exp(acath_glm3[["coefficients"]][["(Intercept)"]] + acath_glm3[["coefficients"]][["age"]]*mean(acath$age) + acath_glm3[["coefficients"]][["choleste"]] *x + acath_glm3[["coefficients"]][["cad.dur"]] * mean(acath$cad.dur)))
femenino =  exp(acath_glm3[["coefficients"]][["(Intercept)"]] + acath_glm3[["coefficients"]][["age"]]*mean(acath$age) + acath_glm3[["coefficients"]][["choleste"]] *x + acath_glm3[["coefficients"]][["cad.dur"]] * mean(acath$cad.dur) + acath_glm3[["coefficients"]][["sex1"]])/(1 + exp(acath_glm3[["coefficients"]][["(Intercept)"]] + acath_glm3[["coefficients"]][["age"]]*mean(acath$age) + acath_glm3[["coefficients"]][["choleste"]] *x + acath_glm3[["coefficients"]][["cad.dur"]] * mean(acath$cad.dur) + acath_glm3[["coefficients"]][["sex1"]]))
plot(x , masculino , type = "line", xlab = "colesterol",ylab = "Probabilidad de estrechamiento de arteria", main = "Prob. de estrechamiento con prom. de edad y duración")
lines(x, femenino)
plot(x , masculino , type = "line", xlab = "colesterol",ylab = "Probabilidad de estrechamiento de arteria", main = "Prob. de estrechamiento con prom. de edad y duración", xlim=c(0,max(acath$choleste)), ylim=c(0,1))
plot(x , masculino , type = "line", xlab = "colesterol",ylab = "Probabilidad de estrechamiento de arteria", main = "Prob. de estrechamiento con prom. de edad y duración", xlim=c(0,max(acath$choleste, na.rm = TRUE)), ylim=c(0,1))
lines(x, femenino)
plot(x , masculino , type = "line", xlab = "colesterol",ylab = "Probabilidad de estrechamiento de arteria", main = "Prob. de estrechamiento con prom. de edad y duración", xlim=c(0,max(acath$choleste, na.rm = TRUE)), ylim=c(0,1), col = "green")
lines(x, femenino, col = "orange")
plot(x , masculino , type = "line", xlab = "colesterol",ylab = "Prob. de estrechamiento de arteria", main = "Prob. de estrechamiento con prom. de edad y duración", xlim=c(0,max(acath$choleste, na.rm = TRUE)), ylim=c(0,1), col = "green")
masculino =  exp(acath_glm3[["coefficients"]][["(Intercept)"]] + acath_glm3[["coefficients"]][["age"]]*mean(acath$age) + acath_glm3[["coefficients"]][["choleste"]] *x + acath_glm3[["coefficients"]][["cad.dur"]] * mean(acath$cad.dur))/(1 + exp(acath_glm3[["coefficients"]][["(Intercept)"]] + acath_glm3[["coefficients"]][["age"]]*mean(acath$age) + acath_glm3[["coefficients"]][["choleste"]] *x + acath_glm3[["coefficients"]][["cad.dur"]] * mean(acath$cad.dur)))
x = seq(min(choleste, na.rm = TRUE), max(choleste, na.rm = TRUE), 10000)
femenino =  exp(acath_glm3[["coefficients"]][["(Intercept)"]] + acath_glm3[["coefficients"]][["age"]]*mean(acath$age) + acath_glm3[["coefficients"]][["choleste"]] *x + acath_glm3[["coefficients"]][["cad.dur"]] * mean(acath$cad.dur) + acath_glm3[["coefficients"]][["sex1"]])/(1 + exp(acath_glm3[["coefficients"]][["(Intercept)"]] + acath_glm3[["coefficients"]][["age"]]*mean(acath$age) + acath_glm3[["coefficients"]][["choleste"]] *x + acath_glm3[["coefficients"]][["cad.dur"]] * mean(acath$cad.dur) + acath_glm3[["coefficients"]][["sex1"]]))
plot(x , masculino , type = "line", xlab = "colesterol",ylab = "Prob. de estrechamiento de arteria", main = "Prob. de estrechamiento con prom. de edad y duración", xlim=c(0,max(acath$choleste, na.rm = TRUE)), ylim=c(0,1), col = "green")
lines(x, femenino, col = "orange")
x = seq(min(choleste, na.rm = TRUE), max(choleste, na.rm = TRUE), 10000)
masculino =  exp(acath_glm3[["coefficients"]][["(Intercept)"]] + acath_glm3[["coefficients"]][["age"]]*mean(acath$age) + acath_glm3[["coefficients"]][["choleste"]] *x + acath_glm3[["coefficients"]][["cad.dur"]] * mean(acath$cad.dur))/(1 + exp(acath_glm3[["coefficients"]][["(Intercept)"]] + acath_glm3[["coefficients"]][["age"]]*mean(acath$age) + acath_glm3[["coefficients"]][["choleste"]] *x + acath_glm3[["coefficients"]][["cad.dur"]] * mean(acath$cad.dur)))
femenino =  exp(acath_glm3[["coefficients"]][["(Intercept)"]] + acath_glm3[["coefficients"]][["age"]]*mean(acath$age) + acath_glm3[["coefficients"]][["choleste"]] *x + acath_glm3[["coefficients"]][["cad.dur"]] * mean(acath$cad.dur) + acath_glm3[["coefficients"]][["sex1"]])/(1 + exp(acath_glm3[["coefficients"]][["(Intercept)"]] + acath_glm3[["coefficients"]][["age"]]*mean(acath$age) + acath_glm3[["coefficients"]][["choleste"]] *x + acath_glm3[["coefficients"]][["cad.dur"]] * mean(acath$cad.dur) + acath_glm3[["coefficients"]][["sex1"]]))
plot(x , masculino , type = "line", xlab = "colesterol",ylab = "Prob. de estrechamiento de arteria", main = "Prob. de estrechamiento con prom. de edad y duración", xlim=c(0,max(acath$choleste, na.rm = TRUE)), ylim=c(0,1), col = "green")
View(acath)
min(acath$choleste)
min(acath$choleste, na.rm = TRUE)
View(acath)
plot(x , masculino , type = "line", xlab = "colesterol",ylab = "Prob. de estrechamiento de arteria", main = "Gráfico XXX. Prob. de estrechamiento", xlim=c(0,max(acath$choleste, na.rm = TRUE)), ylim=c(0,1), col = "green")
lines(x, femenino, col = "orange")
legend()
plot(x , masculino , type = "line", xlab = "colesterol",ylab = "Prob. de estrechamiento de arteria", main = "Gráfico XXX. Prob. de estrechamiento", xlim=c(0,max(acath$choleste, na.rm = TRUE)), ylim=c(0,1), col = "green")
x = seq(min_cholest, max_cholest, 0.1)
gpa = 1
masculino =  exp(acath_glm3[["coefficients"]][["(Intercept)"]] + acath_glm3[["coefficients"]][["age"]]*mean(acath$age) + acath_glm3[["coefficients"]][["choleste"]] *x + acath_glm3[["coefficients"]][["cad.dur"]] * mean(acath$cad.dur))/(1 + exp(acath_glm3[["coefficients"]][["(Intercept)"]] + acath_glm3[["coefficients"]][["age"]]*mean(acath$age) + acath_glm3[["coefficients"]][["choleste"]] *x + acath_glm3[["coefficients"]][["cad.dur"]] * mean(acath$cad.dur)))
femenino =  exp(acath_glm3[["coefficients"]][["(Intercept)"]] + acath_glm3[["coefficients"]][["age"]]*mean(acath$age) + acath_glm3[["coefficients"]][["choleste"]] *x + acath_glm3[["coefficients"]][["cad.dur"]] * mean(acath$cad.dur) + acath_glm3[["coefficients"]][["sex1"]])/(1 + exp(acath_glm3[["coefficients"]][["(Intercept)"]] + acath_glm3[["coefficients"]][["age"]]*mean(acath$age) + acath_glm3[["coefficients"]][["choleste"]] *x + acath_glm3[["coefficients"]][["cad.dur"]] * mean(acath$cad.dur) + acath_glm3[["coefficients"]][["sex1"]]))
plot(x , masculino , type = "line", xlab = "colesterol",ylab = "Prob. de estrechamiento de arteria", main = "Gráfico XXX. Prob. de estrechamiento", xlim=c(0,max(acath$choleste, na.rm = TRUE)), ylim=c(0,1), col = "green")
install.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon', 'pbdZMQ',
'devtools', 'uuid', 'digest'))
install.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon', 'pbdZMQ',
'devtools', 'uuid', 'digest'))
install.packages('IRkernel')
numeros <- c(1226976, 222634, 331623, 441637, 551641,
111599, 111611, 111623, 111637, 111641,
128339, 131707, 135391, 136337, 137947,
123997, 107971, 111997, 221987 , 334991,
200891, 445157, 574817, 700001, 899401,
100003, 100019, 111317, 111323 , 131071,
200443,200461,200467,200569,200587,
103087, 103391, 103613, 104087, 104309, 104549,
130729, 312679, 573341, 730487, 997973)
numeros_ord <- sort(numeros)
numeros_ord
X <- data.table(
grp = sample(1:10),
xval = rnorm(10)
)
library(data.table)
X <- data.table(
grp = sample(1:10),
xval = rnorm(10)
)
Y <- data.table(
grp = sample(rep(1:10, 2)),
yval = rnorm(20)
)
View(X)
View(Y)
setkey(X, grp)
setkey(Y, grp)
X[Y]
dt <- fread("https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data", header=FALSE)
names(dt) <- c("age", "workclass", "fnlwgt", "education", "education_num", "marital_status", "occupation", "relationship", "race", "sex", "capital_gain", "capital_loss","hours_per_week", "native_country", "label")
dt[occupation == 'Tech-support', mean(age)]
#Optimizacion Bayesiana de hiperparametros de  rpart
#limpio la memoria
rm( list=ls() )  #remove all objects
gc()             #garbage collection
require("data.table")
require("rlist")
require("rpart")
require("parallel")
#paquetes necesarios para la Bayesian Optimization
require("DiceKriging")
require("mlrMBO")
#Defino la  Optimizacion Bayesiana
kBO_iter  <- 100   #cantidad de iteraciones de la Optimizacion Bayesiana
hs  <- makeParamSet(
makeNumericParam("cp"       , lower= -1   , upper=    0.1),
makeIntegerParam("minsplit" , lower=  1L  , upper= 8000L),  #la letra L al final significa ENTERO
makeIntegerParam("minbucket", lower=  1L  , upper= 2000L),
makeIntegerParam("maxdepth" , lower=  3L  , upper=   20L),
forbidden = quote( minbucket > 0.5*minsplit ) )             # minbuket NO PUEDE ser mayor que la mitad de minsplit
ksemilla_azar  <- 100049   #cambiar por la primer semilla
#------------------------------------------------------------------------------
#graba a un archivo los componentes de lista
#para el primer registro, escribe antes los titulos
loguear  <- function( reg, arch=NA, folder="./work/", ext=".txt", verbose=TRUE )
{
archivo  <- arch
if( is.na(arch) )  archivo  <- paste0( folder, substitute( reg), ext )
if( !file.exists( archivo ) )  #Escribo los titulos
{
linea  <- paste0( "fecha\t",
paste( list.names(reg), collapse="\t" ), "\n" )
cat( linea, file=archivo )
}
linea  <- paste0( format(Sys.time(), "%Y%m%d %H%M%S"),  "\t",     #la fecha y hora
gsub( ", ", "\t", toString( reg ) ),  "\n" )
cat( linea, file=archivo, append=TRUE )  #grabo al archivo
if( verbose )  cat( linea )   #imprimo por pantalla
}
#------------------------------------------------------------------------------
#particionar agrega una columna llamada fold a un dataset que consiste en una particion estratificada segun agrupa
# particionar( data=dataset, division=c(70,30), agrupa=clase_ternaria, seed=semilla)   crea una particion 70, 30
# particionar( data=dataset, division=c(1,1,1,1,1), agrupa=clase_ternaria, seed=semilla)   divide el dataset en 5 particiones
particionar  <- function( data, division, agrupa="", campo="fold", start=1, seed=NA )
{
if( !is.na( seed)  )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x ) }, division, seq( from=start, length.out=length(division) )  ) )
data[ , (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
#------------------------------------------------------------------------------
#fold_test  tiene el numero de fold que voy a usar para testear, entreno en el resto de los folds
#param tiene los hiperparametros del arbol
ArbolSimple  <- function( fold_test, data, param )
{
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",
data= data[ fold != fold_test, ],  #entreno en todo MENOS el fold_test que uso para testing
xval= 0,
control= param )
#aplico el modelo a los datos de testing
prediccion  <- predict( modelo,
data[ fold==fold_test, ],  #aplico el modelo sobre los datos de testing
type= "prob")   #quiero que me devuelva probabilidades
prob_baja2  <- prediccion[, "BAJA+2"]  #esta es la probabilidad de baja
#calculo la ganancia
ganancia_testing  <- data[ fold==fold_test ][ prob_baja2 > 1/60,
sum( ifelse( clase_ternaria=="BAJA+2", 59000, -1000 ) )]
return( ganancia_testing )  #esta es la ganancia sobre el fold de testing, NO esta normalizada
}
#------------------------------------------------------------------------------
ArbolesCrossValidation  <- function( data, param, qfolds, pagrupa, semilla )
{
divi  <- rep( 1, qfolds )  # generalmente  c(1, 1, 1, 1, 1 )  cinco unos
particionar( data, divi, seed=semilla, agrupa=pagrupa )  #particiono en dataset en folds
ganancias  <- mcmapply( ArbolSimple,
seq(qfolds), # 1 2 3 4 5
MoreArgs= list( data, param),
SIMPLIFY= FALSE,
mc.cores= 1 )   #se puede subir a qfolds si posee Linux o Mac OS
data[ , fold := NULL ]
#devuelvo la primer ganancia y el promedio
ganancia_promedio  <- mean( unlist( ganancias ) )   #promedio las ganancias
ganancia_promedio_normalizada  <- ganancia_promedio * qfolds  #aqui normalizo la ganancia
return( ganancia_promedio_normalizada )
}
#------------------------------------------------------------------------------
#esta funcion solo puede recibir los parametros que se estan optimizando
#el resto de los parametros, lamentablemente se pasan como variables globales
EstimarGanancia  <- function( x )
{
GLOBAL_iteracion  <<-  GLOBAL_iteracion + 1
xval_folds  <- 5
ganancia  <- ArbolesCrossValidation( dataset,
param= x, #los hiperparametros del arbol
qfolds= xval_folds,  #la cantidad de folds
pagrupa= "clase_ternaria",
semilla= ksemilla_azar )
#logueo
xx  <- x
xx$xval_folds  <-  xval_folds
xx$ganancia  <- ganancia
xx$iteracion <- GLOBAL_iteracion
loguear( xx,  arch= archivo_log )
return( ganancia )
}
#------------------------------------------------------------------------------
#Aqui empieza el programa
setwd( "CD C:/Users/ARI/Desktop/ITBA/5.Mineria" )
#cargo el dataset
dataset  <- fread("./datasets/paquete_premium_202011.csv")   #donde entreno
#creo la carpeta donde va el experimento
# HT  representa  Hiperparameter Tuning
dir.create( "./labo/exp/",  showWarnings = FALSE )
dir.create( "./labo/exp/HT3210/", showWarnings = FALSE )
setwd("CD C:/Users/ARI/Desktop/ITBA/5.Mineria/labo/exp/HT3210/")   #Establezco el Working Directory DEL EXPERIMENTO
archivo_log  <- "HT321.txt"
archivo_BO   <- "HT321.RDATA"
#leo si ya existe el log, para retomar en caso que se se corte el programa
GLOBAL_iteracion  <- 0
if( file.exists(archivo_log) )
{
tabla_log  <- fread( archivo_log )
GLOBAL_iteracion  <- nrow( tabla_log )
}
#Aqui comienza la configuracion de la Bayesian Optimization
funcion_optimizar  <- EstimarGanancia
configureMlr( show.learner.output= FALSE)
#configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar
#por favor, no desesperarse por lo complejo
obj.fun  <- makeSingleObjectiveFunction(
fn=       funcion_optimizar,
minimize= FALSE,   #estoy Maximizando la ganancia
noisy=    TRUE,
par.set=  hs,
has.simple.signature = FALSE
)
ctrl  <- makeMBOControl( save.on.disk.at.time= 600,  save.file.path= archivo_BO)
ctrl  <- setMBOControlTermination(ctrl, iters= kBO_iter )
ctrl  <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())
surr.km  <- makeLearner("regr.km", predict.type= "se", covtype= "matern3_2", control= list(trace= TRUE))
#inicio la optimizacion bayesiana
if( !file.exists( archivo_BO ) ) {
run  <- mbo(obj.fun, learner = surr.km, control = ctrl)
} else  run  <- mboContinue( archivo_BO )   #retomo en caso que ya exista
#Optimizacion Bayesiana de hiperparametros de  rpart
#limpio la memoria
rm( list=ls() )  #remove all objects
gc()             #garbage collection
require("data.table")
require("rlist")
require("rpart")
require("parallel")
#paquetes necesarios para la Bayesian Optimization
require("DiceKriging")
require("mlrMBO")
#Defino la  Optimizacion Bayesiana
kBO_iter  <- 100   #cantidad de iteraciones de la Optimizacion Bayesiana
hs  <- makeParamSet(
makeNumericParam("cp"       , lower= -1   , upper=    0.1),
makeIntegerParam("minsplit" , lower=  1L  , upper= 8000L),  #la letra L al final significa ENTERO
makeIntegerParam("minbucket", lower=  1L  , upper= 2000L),
makeIntegerParam("maxdepth" , lower=  3L  , upper=   20L),
forbidden = quote( minbucket > 0.5*minsplit ) )             # minbuket NO PUEDE ser mayor que la mitad de minsplit
ksemilla_azar  <- 100049   #cambiar por la primer semilla
#------------------------------------------------------------------------------
#graba a un archivo los componentes de lista
#para el primer registro, escribe antes los titulos
loguear  <- function( reg, arch=NA, folder="./work/", ext=".txt", verbose=TRUE )
{
archivo  <- arch
if( is.na(arch) )  archivo  <- paste0( folder, substitute( reg), ext )
if( !file.exists( archivo ) )  #Escribo los titulos
{
linea  <- paste0( "fecha\t",
paste( list.names(reg), collapse="\t" ), "\n" )
cat( linea, file=archivo )
}
linea  <- paste0( format(Sys.time(), "%Y%m%d %H%M%S"),  "\t",     #la fecha y hora
gsub( ", ", "\t", toString( reg ) ),  "\n" )
cat( linea, file=archivo, append=TRUE )  #grabo al archivo
if( verbose )  cat( linea )   #imprimo por pantalla
}
#------------------------------------------------------------------------------
#particionar agrega una columna llamada fold a un dataset que consiste en una particion estratificada segun agrupa
# particionar( data=dataset, division=c(70,30), agrupa=clase_ternaria, seed=semilla)   crea una particion 70, 30
# particionar( data=dataset, division=c(1,1,1,1,1), agrupa=clase_ternaria, seed=semilla)   divide el dataset en 5 particiones
particionar  <- function( data, division, agrupa="", campo="fold", start=1, seed=NA )
{
if( !is.na( seed)  )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x ) }, division, seq( from=start, length.out=length(division) )  ) )
data[ , (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
#------------------------------------------------------------------------------
#fold_test  tiene el numero de fold que voy a usar para testear, entreno en el resto de los folds
#param tiene los hiperparametros del arbol
ArbolSimple  <- function( fold_test, data, param )
{
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",
data= data[ fold != fold_test, ],  #entreno en todo MENOS el fold_test que uso para testing
xval= 0,
control= param )
#aplico el modelo a los datos de testing
prediccion  <- predict( modelo,
data[ fold==fold_test, ],  #aplico el modelo sobre los datos de testing
type= "prob")   #quiero que me devuelva probabilidades
prob_baja2  <- prediccion[, "BAJA+2"]  #esta es la probabilidad de baja
#calculo la ganancia
ganancia_testing  <- data[ fold==fold_test ][ prob_baja2 > 1/60,
sum( ifelse( clase_ternaria=="BAJA+2", 59000, -1000 ) )]
return( ganancia_testing )  #esta es la ganancia sobre el fold de testing, NO esta normalizada
}
#------------------------------------------------------------------------------
ArbolesCrossValidation  <- function( data, param, qfolds, pagrupa, semilla )
{
divi  <- rep( 1, qfolds )  # generalmente  c(1, 1, 1, 1, 1 )  cinco unos
particionar( data, divi, seed=semilla, agrupa=pagrupa )  #particiono en dataset en folds
ganancias  <- mcmapply( ArbolSimple,
seq(qfolds), # 1 2 3 4 5
MoreArgs= list( data, param),
SIMPLIFY= FALSE,
mc.cores= 1 )   #se puede subir a qfolds si posee Linux o Mac OS
data[ , fold := NULL ]
#devuelvo la primer ganancia y el promedio
ganancia_promedio  <- mean( unlist( ganancias ) )   #promedio las ganancias
ganancia_promedio_normalizada  <- ganancia_promedio * qfolds  #aqui normalizo la ganancia
return( ganancia_promedio_normalizada )
}
#------------------------------------------------------------------------------
#esta funcion solo puede recibir los parametros que se estan optimizando
#el resto de los parametros, lamentablemente se pasan como variables globales
EstimarGanancia  <- function( x )
{
GLOBAL_iteracion  <<-  GLOBAL_iteracion + 1
xval_folds  <- 5
ganancia  <- ArbolesCrossValidation( dataset,
param= x, #los hiperparametros del arbol
qfolds= xval_folds,  #la cantidad de folds
pagrupa= "clase_ternaria",
semilla= ksemilla_azar )
#logueo
xx  <- x
xx$xval_folds  <-  xval_folds
xx$ganancia  <- ganancia
xx$iteracion <- GLOBAL_iteracion
loguear( xx,  arch= archivo_log )
return( ganancia )
}
#------------------------------------------------------------------------------
#Aqui empieza el programa
setwd( "C:/Users/ARI/Desktop/ITBA/5.Mineria" )
#cargo el dataset
dataset  <- fread("./datasets/paquete_premium_202011.csv")   #donde entreno
#creo la carpeta donde va el experimento
# HT  representa  Hiperparameter Tuning
dir.create( "./labo/exp/",  showWarnings = FALSE )
dir.create( "./labo/exp/HT3210/", showWarnings = FALSE )
setwd("C:/Users/ARI/Desktop/ITBA/5.Mineria/labo/exp/HT3210/")   #Establezco el Working Directory DEL EXPERIMENTO
archivo_log  <- "HT321.txt"
archivo_BO   <- "HT321.RDATA"
#leo si ya existe el log, para retomar en caso que se se corte el programa
GLOBAL_iteracion  <- 0
if( file.exists(archivo_log) )
{
tabla_log  <- fread( archivo_log )
GLOBAL_iteracion  <- nrow( tabla_log )
}
#Aqui comienza la configuracion de la Bayesian Optimization
funcion_optimizar  <- EstimarGanancia
configureMlr( show.learner.output= FALSE)
#configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar
#por favor, no desesperarse por lo complejo
obj.fun  <- makeSingleObjectiveFunction(
fn=       funcion_optimizar,
minimize= FALSE,   #estoy Maximizando la ganancia
noisy=    TRUE,
par.set=  hs,
has.simple.signature = FALSE
)
ctrl  <- makeMBOControl( save.on.disk.at.time= 600,  save.file.path= archivo_BO)
ctrl  <- setMBOControlTermination(ctrl, iters= kBO_iter )
ctrl  <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())
surr.km  <- makeLearner("regr.km", predict.type= "se", covtype= "matern3_2", control= list(trace= TRUE))
#inicio la optimizacion bayesiana
if( !file.exists( archivo_BO ) ) {
run  <- mbo(obj.fun, learner = surr.km, control = ctrl)
} else  run  <- mboContinue( archivo_BO )   #retomo en caso que ya exista
